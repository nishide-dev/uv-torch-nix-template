{
{# Extract values from preset #}
{% if pytorch_cuda_preset == 'pytorch-2.9.0-cuda-12.6' %}
  {% set pytorch_version = '2.9.0' %}
  {% set cuda_version = '12.6' %}
  {% set cudnn_version = '9.16.0' %}
{% elif pytorch_cuda_preset == 'pytorch-2.9.0-cuda-13.0' %}
  {% set pytorch_version = '2.9.0' %}
  {% set cuda_version = '13.0' %}
  {% set cudnn_version = '9.16.0' %}
{% elif pytorch_cuda_preset == 'pytorch-2.8.0-cuda-12.6' %}
  {% set pytorch_version = '2.8.0' %}
  {% set cuda_version = '12.6' %}
  {% set cudnn_version = '9.16.0' %}
{% elif pytorch_cuda_preset == 'pytorch-2.8.0-cuda-12.8' %}
  {% set pytorch_version = '2.8.0' %}
  {% set cuda_version = '12.8' %}
  {% set cudnn_version = '9.16.0' %}
{% elif pytorch_cuda_preset == 'pytorch-2.7.1-cuda-12.6' %}
  {% set pytorch_version = '2.7.1' %}
  {% set cuda_version = '12.6' %}
  {% set cudnn_version = '9.16.0' %}
{% elif pytorch_cuda_preset == 'pytorch-2.7.1-cuda-11.8' %}
  {% set pytorch_version = '2.7.1' %}
  {% set cuda_version = '11.8' %}
  {% set cudnn_version = '8.9.7' %}
{% elif pytorch_cuda_preset == 'pytorch-2.6.0-cuda-12.4' %}
  {% set pytorch_version = '2.6.0' %}
  {% set cuda_version = '12.4' %}
  {% set cudnn_version = '9.1.0' %}
{% elif pytorch_cuda_preset == 'pytorch-2.6.0-cuda-11.8' %}
  {% set pytorch_version = '2.6.0' %}
  {% set cuda_version = '11.8' %}
  {% set cudnn_version = '8.9.7' %}
{% elif pytorch_cuda_preset == 'pytorch-2.5.1-cuda-12.4' %}
  {% set pytorch_version = '2.5.1' %}
  {% set cuda_version = '12.4' %}
  {% set cudnn_version = '9.1.0' %}
{% elif pytorch_cuda_preset == 'pytorch-2.5.1-cuda-12.1' %}
  {% set pytorch_version = '2.5.1' %}
  {% set cuda_version = '12.1' %}
  {% set cudnn_version = '9.1.0' %}
{% elif pytorch_cuda_preset == 'pytorch-2.5.1-cuda-11.8' %}
  {% set pytorch_version = '2.5.1' %}
  {% set cuda_version = '11.8' %}
  {% set cudnn_version = '8.9.7' %}
{% elif pytorch_cuda_preset == 'pytorch-2.4.1-cuda-12.4' %}
  {% set pytorch_version = '2.4.1' %}
  {% set cuda_version = '12.4' %}
  {% set cudnn_version = '8.9.7' %}
{% elif pytorch_cuda_preset == 'pytorch-2.4.1-cuda-12.1' %}
  {% set pytorch_version = '2.4.1' %}
  {% set cuda_version = '12.1' %}
  {% set cudnn_version = '8.9.7' %}
{% elif pytorch_cuda_preset == 'pytorch-2.4.1-cuda-11.8' %}
  {% set pytorch_version = '2.4.1' %}
  {% set cuda_version = '11.8' %}
  {% set cudnn_version = '8.9.7' %}
{% elif pytorch_cuda_preset == 'pytorch-2.3.1-cuda-12.1' %}
  {% set pytorch_version = '2.3.1' %}
  {% set cuda_version = '12.1' %}
  {% set cudnn_version = '8.9.2' %}
{% elif pytorch_cuda_preset == 'pytorch-2.3.1-cuda-11.8' %}
  {% set pytorch_version = '2.3.1' %}
  {% set cuda_version = '11.8' %}
  {% set cudnn_version = '8.9.2' %}
{# else: use custom values from user input #}
{% endif %}

  description = "Deep Learning Environment: uv + PyTorch + Managed CUDA (NixOS Compatible)";

  inputs = {
    nixpkgs.url = "github:NixOS/nixpkgs/nixos-unstable";
    flake-utils.url = "github:numtide/flake-utils";
  };

  outputs = { self, nixpkgs, flake-utils }:
    flake-utils.lib.eachDefaultSystem (system:
      let
        # CUDA対応のpkgsを作成（Unfreeパッケージを許可）
        pkgs = import nixpkgs {
          inherit system;
          config = {
            allowUnfree = true;  # CUDA関連パッケージはunfree
            cudaSupport = true;
          };
        };

        # ---------------------------------------------------------
        # 【重要】CUDAバージョンの管理ポイント
        # ここで指定したバージョンのToolkitが環境に展開される
        # 利用可能: cudaPackages_11_8, cudaPackages_12_1, cudaPackages
        # ---------------------------------------------------------
        cudaPackages = pkgs.cudaPackages;  # デフォルトバージョンを使用

        # Pythonバージョンの選択（既存プロジェクトの.python-versionから取得）
        pythonVersionFile = builtins.readFile ./.python-version;
        pythonVersionClean = builtins.replaceStrings ["\n" " "] ["" ""] pythonVersionFile;
        pythonVersionAttr = builtins.replaceStrings ["."] [""] pythonVersionClean;
        python = pkgs."python${pythonVersionAttr}" or pkgs.python312;

        # システムレベルの依存関係
        # Python環境が動くために必要なライブラリ群
        systemDependencies = with pkgs; [
          stdenv.cc.cc.lib  # libstdc++.so.6 - PyTorchに必須
          zlib
          glib
          git
          curl
          # ビルドツール（flash-attn等のコンパイルに必要）
          ninja
          cmake
          which
          pkg-config
        ];

        # CUDA関連ライブラリ
        cudaLibs = with cudaPackages; [
          cuda_cudart       # CUDA Runtime
          cuda_nvcc         # CUDA Compiler
          cudnn             # cuDNN
          libcublas         # cuBLAS
          {% if additional_cuda_libs %}
          # 追加ライブラリ: {{ additional_cuda_libs }}
          {% for lib in additional_cuda_libs.split(',') if lib.strip() %}
          {{ lib.strip() }}
          {% endfor %}
          {% endif %}
        ];

      in {
        devShells.default = pkgs.mkShell {
          name = "cuda-torch-uv-shell";

          packages = [
            # Python環境
            python
            pkgs.uv

            # Node.js環境（AI CLIツール用）
            pkgs.nodejs_22
          ] ++ systemDependencies ++ cudaLibs;

          # nix-ldのためのライブラリパス設定
          # これにより未パッチのバイナリ（PyTorchのWheel等）が動作可能になる
          NIX_LD_LIBRARY_PATH = pkgs.lib.makeLibraryPath (systemDependencies ++ cudaLibs);
          NIX_LD = pkgs.lib.fileContents "${pkgs.stdenv.cc}/nix-support/dynamic-linker";

          env = {
            # uvにNix提供のPythonを使用させる
            UV_PYTHON = "${python}/bin/python";
            UV_PYTHON_DOWNLOADS = "never";

            # npmグローバルインストール先をローカルに設定
            # Note: This will be set in shellHook to properly expand $HOME

            # CUDA環境変数
            # 多くのビルドスクリプトが参照するCUDA_HOMEを設定
            CUDA_HOME = "${cudaPackages.cudatoolkit}";
            CUDA_PATH = "${cudaPackages.cudatoolkit}";
            CUDNN_PATH = "${cudaPackages.cudnn}";
          };

          shellHook = ''
            # カラー出力
            GREEN='\033[0;32m'
            YELLOW='\033[1;33m'
            BLUE='\033[0;34m'
            NC='\033[0m' # No Color

            # --- ライブラリパス (LD_LIBRARY_PATH) の構築 ---
            # これにより、TorchのWheelがNixストア内のライブラリを見つけられるようにする
            # 【最重要】/run/opengl-driver/lib を含めることでlibcuda.soが見つかる
            export LD_LIBRARY_PATH="${pkgs.lib.makeLibraryPath (systemDependencies ++ cudaLibs)}:/run/opengl-driver/lib:''${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}"

            # libstdc++を優先的に使用（ABI互換性のため）
            export LD_LIBRARY_PATH="${pkgs.stdenv.cc.cc.lib}/lib:$LD_LIBRARY_PATH"

            # コンパイル用フラグ（flash-attn等をビルドする場合に必要）
            export EXTRA_LDFLAGS="-L/lib -L${cudaPackages.cudatoolkit}/lib"
            export EXTRA_CCFLAGS="-I/usr/include -I${cudaPackages.cudatoolkit}/include"

            # npmグローバルインストール先を設定
            export NPM_CONFIG_PREFIX="''${HOME}/.npm-global"
            export PATH="''${HOME}/.npm-global/bin:$PATH"
            mkdir -p "''${HOME}/.npm-global/bin"

            # CUDAコンパイラのPATH追加
            export PATH="${cudaPackages.cuda_nvcc}/bin:$PATH"

            # 仮想環境の初期化と有効化
            if [ ! -d ".venv" ]; then
              echo -e "''${YELLOW}Initializing uv virtual environment...''${NC}"
              uv venv
            fi
            source .venv/bin/activate

            # AI CLIツールを静かにインストール（未インストールの場合のみ）
            if ! command -v claude &> /dev/null; then
              npm install -g @anthropic-ai/claude-code &>/dev/null || curl -fsSL https://claude.ai/install.sh | bash &>/dev/null
            fi
            if ! command -v codex &> /dev/null; then
              npm install -g @openai/codex &>/dev/null || true
            fi
            if ! command -v gemini &> /dev/null; then
              npm install -g @google/gemini-cli &>/dev/null || true
            fi

            # GPU情報の取得
            GPU_NAME=""
            if command -v nvidia-smi &> /dev/null; then
              GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader 2>/dev/null | head -1)
            fi

            # バージョン情報
            PYTHON_VER=$(python --version 2>&1 | cut -d' ' -f2)
            UV_VER=$(uv --version 2>&1 | cut -d' ' -f2)

            if [ "''${VERBOSE_INIT:-0}" = "1" ]; then
              # 詳細モード
              echo ""
              echo "=================================================="
              echo -e "''${GREEN}PyTorch/CUDA Development Environment Ready''${NC}"
              echo "=================================================="
              echo "Python:      $PYTHON_VER"
              echo "uv:          $UV_VER"
              echo "CUDA:        {{ cuda_version }}"
              echo "PyTorch:     {{ pytorch_version }}"
              [ -n "$GPU_NAME" ] && echo "GPU:         $GPU_NAME"
              echo "Node.js:     $(node --version)"
              echo "npm:         $(npm --version)"

              if command -v claude &> /dev/null; then
                echo "claude:      $(claude --version 2>/dev/null || echo 'installed')"
              fi
              if command -v codex &> /dev/null; then
                echo "codex:       $(codex --version 2>/dev/null || echo 'installed')"
              fi
              if command -v gemini &> /dev/null; then
                echo "gemini:      $(gemini --version 2>/dev/null || echo 'installed')"
              fi

              echo ""
              echo "Commands:"
              echo "  uv sync                          # Install dependencies"
              echo "  uv run python -c 'import torch; print(torch.cuda.is_available())'  # Check CUDA"
              echo "  uv add flash-attn --no-build-isolation  # Add packages with compilation"
              echo "  claude / codex / gemini          # AI CLI tools"
              echo ""
              echo "Docs: docs/CUDA_SETUP.md, docs/NIX_SETUP.md, docs/AI_CLI_TOOLS.md"
              echo "=================================================="
              echo ""
            else
              # 簡潔モード（デフォルト）
              GPU_INFO=""
              [ -n "$GPU_NAME" ] && GPU_INFO=" (GPU: $GPU_NAME)"
              echo -e "''${GREEN}✓''${NC} PyTorch {{ pytorch_version }} + CUDA {{ cuda_version }}$GPU_INFO"
            fi
          '';
        };
      }
    );
}
